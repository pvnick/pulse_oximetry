{
 "metadata": {
  "name": "",
  "signature": "sha256:1eae7b56088e779c57a61fc39cfaed525719dc375b7617be728a3306d60ec3ca"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Pulse Oximetry for Entire Sample"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_file_path = '/home/pvnick/Downloads/andreas_dtw_cast_experimental_processed.csv'\n",
      "#data_file_path = '/Users/patricktighe/Documents/Python Projects/pulse_oximetry/andreas_dtw_cast_experimental_processed.csv'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%pylab --no-import-all inline\n",
      "\n",
      "import locale\n",
      "import scipy as sc\n",
      "import scipy.stats\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import os\n",
      "from scipy.interpolate import interp1d\n",
      "import math\n",
      "import string\n",
      "import re\n",
      "\n",
      "np.random.seed(10)\n",
      "plt.rcParams['mathtext.default'] = 'it' #'regular'\n",
      "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "'en_US.UTF-8'"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw_data = pd.read_csv(data_file_path)\n",
      "# raw_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_vals = raw_data[raw_data.columns[4:]]\n",
      "all_vals.columns = pd.Index([int(column_name) - 1 for column_name in all_vals.columns]) #correct column index offset\n",
      "all_vals1d = pd.Series(all_vals.values.flatten())\n",
      "all_vals1d_missing_removed = all_vals1d[all_vals1d > -1]\n",
      "global_mean = all_vals1d_missing_removed.mean()\n",
      "global_std = all_vals1d_missing_removed.std()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_subjects_valsld_missing = all_vals1d[all_vals1d == -1].count()\n",
      "print(float(all_subjects_valsld_missing) / all_vals1d.count())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0491869775524\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def piecewise_aggregate_approximation(series, paa_size):\n",
      "    paa_size = int(paa_size)\n",
      "    series_length = int(series.count())\n",
      "    #take care of the special case where there is no dimensionality reduction\n",
      "    if series_length == paa_size:\n",
      "        paa = series\n",
      "    else:\n",
      "        if series_length % paa_size == 0:\n",
      "            paa = series.reshape([series_length / paa_size, paa_size], order=\"F\").mean(axis=0)\n",
      "        else:\n",
      "            temp = pd.DataFrame(series).T.reindex(index = xrange(paa_size), method=\"ffill\")\n",
      "            expanded_sub_section = temp.values.reshape(paa_size * series_length, order=\"F\")\n",
      "            paa = expanded_sub_section.reshape([series_length, paa_size], order=\"F\").mean(axis=0)\n",
      "    return pd.Series(paa)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#For the cuts, we may wish to bound asymmetrically, such that we have a floor of ?70% below which our signal is considered 'bad'; the functional range is realy above 80%\n",
      "#Paul: should I try cutting those off? It may be good to slice those signals out when we filter out the -1s\n",
      "#PT: How would you perform the cutoff? Anything below 70% -> 70%? Maybe keep this in our pocket if we think we need to process the data a bit more?\n",
      "def get_cuts(paa_series, alphabet_size):\n",
      "    alphabet_size = int(alphabet_size)\n",
      "    relevant_cut_points = np.zeros(alphabet_size + 1)\n",
      "    for i in range(alphabet_size + 1): \n",
      "        relevant_cut_points[i] = sc.stats.norm.ppf(q=i / float(alphabet_size), scale = 1) \n",
      "    relevant_cut_points_series = pd.Series(relevant_cut_points)\n",
      "    cuts = paa_series.apply(lambda paa_element: np.sum(relevant_cut_points <= paa_element))\n",
      "    return cuts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#No longer needed?\n",
      "\n",
      "# interpolation_func = interp1d(x=pd.concat([pd.Series(np.arange(1,10+1)), pd.Series(np.arange(20,30))]),\n",
      "#                               y=np.arange(1,100, 5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#PT: If I understand this correctly, we are compressing 10-second epochs into a single frame? \n",
      "\n",
      "patient_saxes = pd.Series(index = raw_data.index)\n",
      "patient_paas = {}\n",
      "\n",
      "#paa_ticks_to_compress determines how many points to include per frame when reducing \n",
      "#dimensionality. this is conceptually similar to moving average, but with the averaging window\n",
      "#stepping forward by paa_ticks_to_compress points instead of 1 point. its slightly more \n",
      "#complicated than that, but thats the basic idea (see piecewise_aggregate_approximation function)\n",
      "\n",
      "paa_ticks_to_compress = 3 #This is a change from earlier runs where =10; now using 3-sec compression\n",
      "sax_alphabet_size = 10 #This is a change from earlier runs where =5; large alphabet for higher-resolution look at smaller degrees of change\n",
      "\n",
      "for patientid in raw_data.index:\n",
      "    vals=pd.Series(raw_data.ix[patientid].values[4:])\n",
      "    missing_values = vals[vals==-1]\n",
      "    missing_values_index = missing_values.index\n",
      "    missing_vals_removed = vals.drop(missing_values_index)\n",
      "    missing_vals_removed_index = missing_vals_removed.index\n",
      "    \n",
      "    min_index = missing_vals_removed_index[0]\n",
      "    max_index = missing_vals_removed_index[-1]\n",
      "    interpolation_func = interp1d(x = missing_vals_removed_index,\n",
      "                                  y = missing_vals_removed)\n",
      "    \n",
      "    interpolated_vals = pd.Series(interpolation_func(np.arange(min_index, max_index + 1)))\n",
      "\n",
      "    local_mean = interpolated_vals.mean()\n",
      "    local_std = interpolated_vals.std()\n",
      "    normalized = (interpolated_vals - local_mean) / local_std \n",
      "\n",
      "    paa = piecewise_aggregate_approximation(normalized, normalized.count() / paa_ticks_to_compress)\n",
      "    patient_paas[patientid] = paa\n",
      "    cuts = get_cuts(paa, sax_alphabet_size)\n",
      "    sax_series = cuts.apply(lambda cut: string.ascii_lowercase[cut - 1])\n",
      "    sax = \"\".join(sax_series.values)\n",
      "    patient_saxes.ix[patientid] = sax\n",
      "\n",
      "patient_saxes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "0     iiiiiiiedddgiiiiiiigddddeiiiiiiddeiiiiiiiiigde...\n",
        "1     jiiiiiiiiiiiiiiiiiiiijjjjjjjjjjjjjjjjijjjjjjjj...\n",
        "2     badddddcabdbaddddddddaadcaadbacdddddddddddbadd...\n",
        "3     hhhhiiiiiiiiiiiiiiiiiiijjjjjjjjjjjjjjjjjjjjjji...\n",
        "4     fiiihffffffeddddddddddddddddddddddddeddfffeddd...\n",
        "5     eeeeeggefgedddcbaaaaddfhihgggiiiiihggeefggggfe...\n",
        "6     cbaaaaaaaaaaaaaaaaaccccccccccccccccbaaaaaaaaaa...\n",
        "7     efeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeedccccde...\n",
        "8     bdffhhhhhhgffdcbaabefghhhhhhhhhhhgffecbddddddd...\n",
        "9     ddddddddddddddddddddddddddddddiiifddddddddfiii...\n",
        "10    iiiiiiiiiiiiiiiiiiiiihhiiiiiiiiiiiiiiiiiiiiiii...\n",
        "11    iiiiiiiiiiijjjiiiiiiiiiiiiiiiiiiiiiiiiijjjjjji...\n",
        "12    gggggggggggggggggggggggggggggggggggggggggggggg...\n",
        "13    bbbbbbbbaaaaaaaaaaabcddddddddddddddddddddddddd...\n",
        "14    ggggggggggggfdddbbbbbcgiiiiiihgfddddbbbbbcdddd...\n",
        "...\n",
        "89     ghjjihfdcefffcbbeffcbaabeggggfbabhjjjiigfghhfd...\n",
        "90     hiihhhiiihgijihhjjjjjiiihiiiiigffgiiiiihhhhhhh...\n",
        "91     gdddegggggggddgggggggggggggddddfgedddddddddddd...\n",
        "92     cccaaacccccccaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaab...\n",
        "93     iiiiiieeehiiiiiiiiiiiiiiiieeeeeeeeeeeeeeeeeefi...\n",
        "94     hgggiihiiiiggeeggghihfegggijjjjjjiijjjjjjiiiii...\n",
        "95     bbeeeecaaabceeeedbbbbbaaaaaceeedbbaabbaaabeeee...\n",
        "96     cdddehiiiiihgghhheccccegffedddfggghhiihhfdddde...\n",
        "97     ffcbaaabcccdfdcccccccccccccccccbabccaabbabefff...\n",
        "98     hhhhhhhhiiiihdbbeeefhhhhhhhhhhhhiiihhhhhhhhhhh...\n",
        "99     cbbbbbbbbaaaabbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbcc...\n",
        "100    geeefgeeeefghhgeeggggggggggggggeecaaaacgijjiii...\n",
        "101    cccccdgdcgcccbaejjjjicgjjjjjjjjjjggggggggggggg...\n",
        "102    ccccccccccccccaaaacccaacccccccccccaaaaaaaaccaa...\n",
        "103    aaaaaaaaaaaaaaaaaaaaaaaaaaaabdggfeeeedddddddcb...\n",
        "Length: 104, dtype: object"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_letter_index(letter):\n",
      "    return string.lowercase.index(letter)\n",
      "\n",
      "def get_raw_sequence_motif_vector(sequence, alphabet_size, motif_length = 2):\n",
      "    l = motif_length\n",
      "    a = alphabet_size\n",
      "    n = a ** l #possible motif combinations\n",
      "    Mp = np.zeros(n) #motif vector\n",
      "    for motif_pos in range(len(sequence) - l + 1):\n",
      "        motif = sequence[motif_pos:motif_pos + l] #current motif\n",
      "        i = 0\n",
      "        for j in np.arange(l):\n",
      "            #where is get_letter_index from? Silly question, but how does this work if it comes at the bottom of this cell?\n",
      "            kj = get_letter_index(motif[j])\n",
      "            i += kj * a ** (l - j - 1)\n",
      "        all_motifs[i] = motif\n",
      "        Mp[i] += 1\n",
      "    return pd.Series(Mp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_motifs = {}\n",
      "motif_length = 2\n",
      "patient_motif_counts = patient_saxes.apply(get_raw_sequence_motif_vector, \n",
      "                                           alphabet_size=sax_alphabet_size,\n",
      "                                           motif_length = motif_length)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Test code for the cell below\n",
      "# sample_indices = np.random.choice(patient_motif_counts.index, size=2, replace=True)\n",
      "# sample = patient_motif_counts.ix[sample_indices]\n",
      "# individual_motif_counts = sample.sum()\n",
      "# total_motif_quantities = individual_motif_counts.sum(axis=1)\n",
      "# x = individual_motif_counts / total_motif_quantities\n",
      "# # print sample\n",
      "# # print individual_motif_counts\n",
      "# x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "0     0.111193\n",
        "1     0.008335\n",
        "2     0.000916\n",
        "3     0.000458\n",
        "4     0.000550\n",
        "5     0.000275\n",
        "6     0.000092\n",
        "7     0.000000\n",
        "8     0.000000\n",
        "9     0.000000\n",
        "10    0.010350\n",
        "11    0.083257\n",
        "12    0.005496\n",
        "13    0.002748\n",
        "14    0.000641\n",
        "...\n",
        "85    0.000000\n",
        "86    0.000183\n",
        "87    0.012182\n",
        "88    0.055688\n",
        "89    0.007602\n",
        "90    0.000000\n",
        "91    0.000000\n",
        "92    0.000000\n",
        "93    0.000000\n",
        "94    0.000000\n",
        "95    0.000183\n",
        "96    0.000092\n",
        "97    0.002381\n",
        "98    0.007694\n",
        "99    0.060267\n",
        "Length: 100, dtype: float64"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This selects a random number of patients, number defined by sample size, with replacement (bootstrapping)\n",
      "# sums the motif counts of those sampled patients on a per-motif basis, then sums this vector which serves as a denominator\n",
      "# for normalization; ulitmatley returns a vector of normalized motif importances v\n",
      "\n",
      "\n",
      "#@Paul: this function now includes iteration, which is the number of replications to run, e.g. the nr listed below?\n",
      "def sample_motif_importances(iteration, sample_size):\n",
      "    sample_indices = np.random.choice(patient_motif_counts.index, size=sample_size, replace=True)\n",
      "    sample = patient_motif_counts.ix[sample_indices]\n",
      "    individual_motif_counts = sample.sum()\n",
      "    total_motif_quantities = individual_motif_counts.sum(axis=1)\n",
      "    x = individual_motif_counts / total_motif_quantities\n",
      "    return x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Measures the proportion of each motif representation across entire cohort \n",
      "\n",
      "pt_cluster_individual_motif_quantity = patient_motif_counts.sum()\n",
      "pt_cluster_total_motif_quantity = pt_cluster_individual_motif_quantity.sum()\n",
      "pt_cluster_props = pt_cluster_individual_motif_quantity / pt_cluster_total_motif_quantity\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Normalizes motif counts over entire cohort on a per-patient basis\n",
      "#NOTE: This is NOT row-normalized!!!\n",
      "patient_motif_props = patient_motif_counts.apply(lambda row: row / row.sum(),axis=1)\n",
      "# patient_motif_props"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Resampling of subjects; row-normalizes\n",
      "#@Paul: Can you please double-check my code here? I put an nr into the sample_motif_importances, but not sure if this is correct\n",
      "\n",
      "nr=1000\n",
      "pt_cluster_size = len(raw_data.index)\n",
      "pt_motif_importance_samples = []\n",
      "\n",
      "for replication in range(nr):\n",
      "    pt_sample = sample_motif_importances(nr,pt_cluster_size)\n",
      "    pt_motif_importance_samples.append(pt_sample)\n",
      "pt_motif_importance_samples = pd.DataFrame(pt_motif_importance_samples)\n",
      "# pt_motif_importance_samples.sum(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pt_numerators = pt_motif_importance_samples.apply(lambda row: row <= pt_cluster_props, axis=1).sum()\n",
      "pt_denominators = pt_motif_importance_samples.count()\n",
      "pt_cdf = pt_numerators / pt_denominators\n",
      "pt_cdf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "0     0.511\n",
        "1     0.506\n",
        "2     0.497\n",
        "3     0.503\n",
        "4     0.511\n",
        "5     0.525\n",
        "6     0.525\n",
        "7     0.531\n",
        "8     0.533\n",
        "9     0.531\n",
        "10    0.494\n",
        "11    0.522\n",
        "12    0.520\n",
        "13    0.466\n",
        "14    0.508\n",
        "...\n",
        "85    0.512\n",
        "86    0.516\n",
        "87    0.481\n",
        "88    0.506\n",
        "89    0.529\n",
        "90    0.584\n",
        "91    0.548\n",
        "92    0.563\n",
        "93    0.564\n",
        "94    0.541\n",
        "95    0.553\n",
        "96    0.537\n",
        "97    0.544\n",
        "98    0.519\n",
        "99    0.527\n",
        "Length: 100, dtype: float64"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "motif_length == 2\n",
      "icon_dimensions =[10,10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=[10,10])\n",
      "ax = plt.axis()\n",
      "\n",
      "icon = pt_cdf\n",
      "icon_side = np.sqrt(icon.count())\n",
      "pixel_data = icon.reshape(icon_dimensions).astype(float)\n",
      "heatmap = plt.pcolor(pixel_data, cmap = plt.cool())\n",
      "plt.gca().invert_yaxis()\n",
      "plt.tick_params(labelbottom='off', labelleft='off')\n",
      "cbar = fig.colorbar(heatmap)\n",
      "cbar.ax.tick_params(labelsize=10)\n",
      "cbar.set_ticks(np.linspace(0, 1, 5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAhcAAAI8CAYAAABCsom9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x602f7d0>"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-5 % 3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "1"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}